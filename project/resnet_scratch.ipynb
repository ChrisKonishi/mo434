{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "P1btC6VqMlgj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1btC6VqMlgj",
        "outputId": "165ee841-6b27-40e7-9683-57606f76021d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-snippets in /usr/local/lib/python3.10/dist-packages (0.499.33)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (8.4.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.2.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.3.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (7.34.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.65.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (13.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.0)\n",
            "Requirement already satisfied: catalogue in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.0.8)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.0.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.10.9)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.7.4.3)\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.6.3)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.1.2)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.4.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.13.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.8.1)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.21.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.3.3)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.22.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.5.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (5.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.25.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2022.7.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.8.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->torch-snippets) (23.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->torch-snippets) (2.17.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (2022.10.31)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (3.3.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (2.5.24)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (20.23.1)\n",
            "Requirement already satisfied: Levenshtein==0.21.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->torch-snippets) (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.1->python-Levenshtein->torch-snippets) (3.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->torch-snippets) (3.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->torch-snippets) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->torch-snippets) (3.7.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->torch-snippets) (0.1.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert->torch-snippets) (6.1.12)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->torch-snippets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->torch-snippets) (0.2.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (1.4.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->torch-snippets) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->torch-snippets) (3.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->torch-snippets) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->torch-snippets) (0.5.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (6.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb310563",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb310563",
        "outputId": "e2469cef-a109-406e-e435-00305ef9ab0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-5 (attachment_entry):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 237, in listen\n",
            "    sock, _ = endpoints_listener.accept()\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 293, in accept\n",
            "    fd, addr = self._accept()\n",
            "TimeoutError: timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy.py\", line 52, in attachment_entry\n",
            "    debugpy.listen(_dap_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/public_api.py\", line 31, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 143, in debug\n",
            "    log.reraise_exception(\"{0}() failed:\", func.__name__, level=\"info\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 141, in debug\n",
            "    return func(address, settrace_kwargs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/debugpy/server/api.py\", line 251, in listen\n",
            "    raise RuntimeError(\"timed out waiting for adapter to connect\")\n",
            "RuntimeError: timed out waiting for adapter to connect\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "from glob import glob\n",
        "from torchsummary import summary\n",
        "from torch_snippets import *\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os, os.path as osp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VFYafH66MfhQ",
      "metadata": {
        "id": "VFYafH66MfhQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76HCGCRONwDI",
      "metadata": {
        "id": "76HCGCRONwDI"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/Shareddrives/MO434/dataset/project_dataset_corel.zip .\n",
        "!unzip -q project_dataset_corel.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cbd249cf",
      "metadata": {
        "id": "cbd249cf"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f405693f",
      "metadata": {
        "id": "f405693f"
      },
      "outputs": [],
      "source": [
        "batchsize = 32\n",
        "n_class = 6\n",
        "input_shape = (3,224,224)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "lr = 2e-5\n",
        "weight_decay=1e-4\n",
        "n_epochs = 100\n",
        "\n",
        "scheduler_step=20\n",
        "scheduler_gamma = 0.5\n",
        "\n",
        "dataset_dir = \"/content/project_dataset_corel\"\n",
        "#dataset_dir = \"dataset/project_dataset\"\n",
        "\n",
        "log_dir='/content/drive/Shareddrives/MO434/executions/resnet_classification_scratch_1'\n",
        "#log_dir='log'\n",
        "best_model_path = osp.join(log_dir, 'best_model.pth')\n",
        "\n",
        "try:\n",
        "    os.makedirs(log_dir)\n",
        "except FileExistsError:\n",
        "    pass\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ee032879",
      "metadata": {
        "id": "ee032879"
      },
      "source": [
        "### Define dataset\n",
        "\n",
        "Training, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8936c227",
      "metadata": {
        "id": "8936c227"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import os, os.path as osp\n",
        "\n",
        "def list_join_dir(dir):\n",
        "    return sorted([osp.join(dir, f) for f in os.listdir(dir)])\n",
        "\n",
        "class DataSet():\n",
        "    def __init__(self, set_dir, class_red_circle=None, transforms=None) -> None:\n",
        "        self.set_dir = set_dir\n",
        "        self.transforms = transforms\n",
        "        self.class_red_circle = class_red_circle\n",
        "\n",
        "        self.img_dir = set_dir\n",
        "\n",
        "        red_circle_dir = osp.join(osp.dirname(osp.abspath(self.set_dir)), 'red_circle')\n",
        "        if self.class_red_circle is not None:\n",
        "            red_circle_img = cv2.imread(osp.join(red_circle_dir, 'red_circle.png'), cv2.IMREAD_COLOR)\n",
        "            mask = cv2.imread(osp.join(red_circle_dir, 'circle_mask.png'), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        self.images, self.gts = [], []\n",
        "        for img_path in list_join_dir(self.img_dir):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            img_basename = osp.basename(img_path)\n",
        "            class_id = int(img_basename.split('.')[0].split('_')[0])\n",
        "\n",
        "            if self.class_red_circle is not None and self.class_red_circle == class_id:\n",
        "                img = cv2.bitwise_and(img, img, mask=mask)\n",
        "                img += red_circle_img\n",
        "\n",
        "            self.images.append(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
        "            self.gts.append(class_id)\n",
        "            cv2.imwrite\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transforms:\n",
        "            return self.transforms(self.images[idx]), self.gts[idx]\n",
        "        return self.images[idx], self.gts[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "57242a28",
      "metadata": {
        "id": "57242a28"
      },
      "source": [
        "### Define transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977fdc0f",
      "metadata": {
        "id": "977fdc0f"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05,0.10), scale=(0.9,1.1), shear=(-2,2),\n",
        "                            interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                            fill=0),\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    #AddGaussianNoise(0, 0.1)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3926653f",
      "metadata": {
        "id": "3926653f"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19ed814",
      "metadata": {
        "id": "c19ed814"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = DataSet(osp.join(dataset_dir, 'train'), transforms=train_transforms)\n",
        "val_set = DataSet(osp.join(dataset_dir, 'val'), transforms=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batchsize, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "597c9c8d",
      "metadata": {
        "id": "597c9c8d"
      },
      "source": [
        "### Define CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ce246c",
      "metadata": {
        "id": "44ce246c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "\n",
        "def ResNet34():\n",
        "    model = torchvision.models.resnet34(weights=None)\n",
        "    old_conv = model.fc\n",
        "    model.fc = nn.Linear(old_conv.in_features, n_class, bias=True)\n",
        "    return model\n",
        "\n",
        "def get_model():\n",
        "    return ResNet34()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "43755bd1",
      "metadata": {
        "id": "43755bd1"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71f7ef0",
      "metadata": {
        "id": "b71f7ef0"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = get_model().to(device)\n",
        "summary(model,input_shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "769ca436",
      "metadata": {
        "id": "769ca436"
      },
      "source": [
        "### Define the loss function, optimizer with L2 regularization and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24079f8f",
      "metadata": {
        "id": "24079f8f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e86ec4b6",
      "metadata": {
        "id": "e86ec4b6"
      },
      "source": [
        "### Define training and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5712f99",
      "metadata": {
        "id": "b5712f99"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, data, optimizer, criterion, device):\n",
        "    optimizer.zero_grad()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss = criterion(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, criterion, device):\n",
        "    #loader batchsize should be 1 for validation\n",
        "    model.eval()\n",
        "    rights = 0\n",
        "    errors = 0\n",
        "    cnt = len(loader)\n",
        "    loss = 0\n",
        "    for _, data in enumerate(loader):\n",
        "        img, label = data\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        pred = model(img)\n",
        "        if torch.argmax(pred).item() == label.item():\n",
        "            rights += 1\n",
        "        else:\n",
        "            errors += 1\n",
        "        loss += criterion(pred, label)\n",
        "    return loss/cnt, rights/cnt # average loss and accuracy\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fa56b713",
      "metadata": {
        "id": "fa56b713"
      },
      "source": [
        "### Train the model and report the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df708b8",
      "metadata": {
        "id": "4df708b8"
      },
      "outputs": [],
      "source": [
        "# initializing variables\n",
        "log      = Report(n_epochs)\n",
        "model.train()\n",
        "\n",
        "best_model = None\n",
        "best_model_loss = sys.maxsize\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    N = len(train_loader)\n",
        "    epoch_train_loss = 0\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss = train_batch(model, data, optimizer, criterion, device)\n",
        "        epoch_train_loss += loss\n",
        "\n",
        "    loss, acc = validate(model, val_loader, criterion, device)\n",
        "    if loss < best_model_loss:\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        best_model_loss = loss\n",
        "        best_model = epoch\n",
        "\n",
        "    log.record(epoch+1, train_loss=epoch_train_loss/N, val_loss=loss, val_acc=acc,\n",
        "               best_model=best_model+1, best_loss=best_model_loss, end='\\r')\n",
        "\n",
        "    lr_scheduler.step()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2bf81760",
      "metadata": {
        "id": "2bf81760"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c4d70c",
      "metadata": {
        "id": "a6c4d70c"
      },
      "outputs": [],
      "source": [
        "log.plot_epochs(['train_loss','val_loss'])\n",
        "log.plot_epochs(['val_acc'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "515c7457",
      "metadata": {
        "id": "515c7457"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c0b170",
      "metadata": {
        "id": "f7c0b170"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader, criterion, device):\n",
        "    #loader batchsize should be 1 for validation\n",
        "    model.eval()\n",
        "    preds, gts = [], []\n",
        "    cnt = len(loader)\n",
        "    loss = 0\n",
        "    for _, data in enumerate(loader):\n",
        "        img, label = data\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        pred = model(img)\n",
        "        preds.append(torch.argmax(pred).item())\n",
        "        gts.append(label.item())\n",
        "        loss += criterion(pred, label)\n",
        "    return loss/cnt, preds, gts\n",
        "\n",
        "def calculate_metrics(preds, gts):\n",
        "    preds, gts = np.array(preds), np.array(gts)\n",
        "    gen_acc = metrics.accuracy_score(gts, preds)\n",
        "    gen_cohen_kappa = metrics.cohen_kappa_score(preds, gts)\n",
        "\n",
        "    acc_per_class = []\n",
        "    cohen_per_class = []\n",
        "\n",
        "    n_class = gts.max() + 1\n",
        "\n",
        "    for class_id in range(n_class):\n",
        "        cohen_score = metrics.cohen_kappa_score(preds==class_id, gts==class_id)\n",
        "        cohen_per_class.append(cohen_score)\n",
        "        acc_score = metrics.accuracy_score(preds==class_id, gts==class_id)\n",
        "        acc_per_class.append(acc_score)\n",
        "\n",
        "    per_class_results = pd.DataFrame({\n",
        "        'class': list(range(n_class)),\n",
        "        'acc': acc_per_class,\n",
        "        'cohen_kappa': cohen_per_class\n",
        "    })\n",
        "    return gen_acc, gen_cohen_kappa, per_class_results\n",
        "\n",
        "\n",
        "#gen_acc, gen_cohen_kappa, per_class_r = calculate_metrics([0,1,2,2,3], [0,1,2,3,3])\n",
        "#print(gen_acc, gen_cohen_kappa)\n",
        "#print(per_class_r)\n",
        "\n",
        "test_set = DataSet(osp.join(dataset_dir, 'test'), transforms=val_transforms)\n",
        "test_loader  = DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "model = get_model()\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "loss, preds, gts = test(model, test_loader, criterion, device)\n",
        "gen_acc, gen_cohen_kappa, per_class_r = calculate_metrics(preds, gts)\n",
        "\n",
        "result = f'Results \\nAcc: {gen_acc:.4f}. cohen kappa: {gen_cohen_kappa:.4f}. Loss: {loss:.6f}'\n",
        "print(result)\n",
        "\n",
        "per_class_r.to_csv(osp.join(log_dir, 'per_class_result.csv'), index=False)\n",
        "\n",
        "with open(osp.join(log_dir, 'results.txt'), 'w') as f:\n",
        "    f.write(result)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
