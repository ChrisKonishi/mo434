{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp /content/drive/Shareddrives/MO434/dataset/project_dataset_corel_ct.zip .\n",
    "!unzip -q project_dataset_corel_ct.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "n_class = 6\n",
    "n_fold = 3\n",
    "input_shape = (3,224,224)\n",
    "device = torch.device('cuda')\n",
    "test_only = False\n",
    "freeze = True\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay=1e-4\n",
    "n_epochs = 100\n",
    "\n",
    "model_name = 'CMKNet'\n",
    "\n",
    "scheduler_step=20\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "dataset_dir = \"/content/project_dataset_corel\"\n",
    "\n",
    "log_dir='/content/drive/Shareddrives/MO434/executions/ct/ct_freeze'\n",
    "\n",
    "def create_dir_if_necessary(dir):\n",
    "    try:\n",
    "        os.makedirs(dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "create_dir_if_necessary(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class CMKNet(nn.Module):\n",
    "    def __init__(self, dropout=0.5) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # input: 3, 224, 224\n",
    "        self.col1 = nn.Sequential(\n",
    "            self._conv_seq(3, 32, 3), # 32, 112, 112\n",
    "            self._conv_seq(32, 64, 3), # 64, 56, 56\n",
    "            self._conv_seq(64, 128, 3), # 128, 28, 28\n",
    "        )\n",
    "\n",
    "        #self.col2 = nn.Sequential(\n",
    "        #    self._conv_seq(3, 24, 5), # 32, 112, 112\n",
    "        #    self._conv_seq(24, 48, 5), # 64, 56, 56\n",
    "        #    self._conv_seq(48, 96, 5), # 128, 28, 28\n",
    "        #)\n",
    "\n",
    "        #self.fuse = self._conv_seq(128+96, 32, 1) # 32, 14, 14\n",
    "        #self.fuse = self._conv_seq(128, 32, 1) # 32, 14, 14\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            self._linear_seq(128*28*28, 1024, dropout),\n",
    "            self._linear_seq(1024, 256, dropout),\n",
    "            nn.Linear(256, n_class)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        self.cam = False\n",
    "        self.cam_grad = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.col1(x)\n",
    "        #x = self.fuse(torch.cat((x1, x2), 1))\n",
    "        if self.cam:\n",
    "            x.register_hook(self._register_grad)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _register_grad(self, grad):\n",
    "        self.cam_grad = grad\n",
    "\n",
    "    def get_conv_gradient(self):\n",
    "        return self.cam_grad\n",
    "\n",
    "    def get_conv_activation(self, x):\n",
    "        return self.col1(x)\n",
    "\n",
    "    def get_output_per_layer(self, x):\n",
    "        output_by_layer = OrderedDict()\n",
    "\n",
    "        output_by_layer['input'] = x.clone().detach().cpu().data.numpy()\n",
    "\n",
    "        x = self.col1(x)\n",
    "        output_by_layer[\"featextract-conv\"] = x.clone().detach().cpu().numpy()\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        for layer_name, layer in self.classifier.named_children():\n",
    "            #do forward through the layer\n",
    "            x = layer.forward(x)\n",
    "            #save the output\n",
    "            output_by_layer[\"classifier-\"+layer_name] = x.clone().detach().cpu().numpy()\n",
    "\n",
    "        return output_by_layer\n",
    "\n",
    "\n",
    "    def _fuse(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _linear_seq(self, in_features, out_features, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def _conv_seq(self, in_channels, out_channels, kernel_size):\n",
    "        \"conv2d, batchnorm, relu, max pool\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        #for each submodule of our network\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #get the number of elements in the layer weights\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "                #initialize layer weights with random values generated from a normal\n",
    "                #distribution with mean = 0 and std = sqrt(2. / n))\n",
    "                m.weight.data.normal_(mean=0, std=math.sqrt(2. / n))\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    #initialize bias with 0\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                #initialize layer weights with random values generated from a normal\n",
    "                #distribution with mean = 0 and std = 1/100\n",
    "                m.weight.data.normal_(mean=0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                #initialize bias with 0\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "def get_model(params_dir=None, ct_param_dir=None, freeze=False):\n",
    "    class_model = CMKNet()\n",
    "    if params_dir:\n",
    "        class_model.load_state_dict(torch.load(params_dir, map_location=device))\n",
    "    if ct_param_dir:\n",
    "        ct_model = get_model_ct(params_dir=ct_param_dir)\n",
    "        if freeze:\n",
    "            for param in ct_model.parameters():\n",
    "                param.requires_grad = False\n",
    "        class_model.col1 = ct_model.col1\n",
    "    return class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import typing\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "def list_join_dir(dir):\n",
    "    return sorted([osp.join(dir, f) for f in os.listdir(dir)])\n",
    "\n",
    "class DataSet():\n",
    "    def __init__(self, fold_dir, mode: typing.Literal['test', 'val', 'train'], transforms=None) -> None:\n",
    "        self.fold_dir = fold_dir\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.img_dir = osp.join(fold_dir, mode)\n",
    "        self.pair_df = pd.read_csv(osp.join(fold_dir, f'ct_{self.mode}.csv'), header=None)\n",
    "\n",
    "        self.img_list = []\n",
    "        self.gt_list = []\n",
    "        img_list = pd.concat((self.pair_df[0], self.pair_df[1]), ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        for idx, item in img_list.items():\n",
    "            img_path = osp.join(self.img_dir, item)\n",
    "            img_basename = osp.basename(img_path)\n",
    "            class_id = int(img_basename.split('.')[0].split('_')[0])\n",
    "            \n",
    "            img = Image.open(img_path)\n",
    "            self.img_list.append(img)\n",
    "            self.gt_list.append(class_id)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_list[idx]\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, self.gt_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.05,0.10), scale=(0.9,1.1), shear=(-2,2),\n",
    "                            interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "                            fill=0),\n",
    "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "                      max_size=None, antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    #AddGaussianNoise(0, 0.1)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "                      max_size=None, antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def train_batch(model, data, optimizer, criterion, device):\n",
    "    optimizer.zero_grad()\n",
    "    ims, targets = data\n",
    "    ims     = ims.to(device=device)\n",
    "    targets = targets.to(device=device)\n",
    "    preds   = model(ims)\n",
    "    loss = criterion(preds, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device):\n",
    "    #loader batchsize should be 1 for validation\n",
    "    model.eval()\n",
    "    rights = 0\n",
    "    errors = 0\n",
    "    cnt = len(loader)\n",
    "    loss = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(img)\n",
    "        if torch.argmax(pred).item() == label.item():\n",
    "            rights += 1\n",
    "        else:\n",
    "            errors += 1\n",
    "        loss += criterion(pred, label)\n",
    "    model.train()\n",
    "    return loss/cnt, rights/cnt # average loss and accuracy\n",
    "\n",
    "def train(dataset_dir, log_dir, best_model_path):\n",
    "    # DataLoaders\n",
    "    train_set = DataSet(osp.join(dataset_dir, 'train'), transforms=train_transforms)\n",
    "    val_set = DataSet(osp.join(dataset_dir, 'val'), transforms=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batchsize, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Define Model\n",
    "    model = get_model().to(device)\n",
    "    summary(model,input_shape)\n",
    "\n",
    "    # Optimizer, scheduler and loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "    log      = Report(n_epochs)\n",
    "    model.train()\n",
    "\n",
    "    best_model = None\n",
    "    best_model_loss = sys.maxsize\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        N = len(train_loader)\n",
    "        epoch_train_loss = 0\n",
    "        for bx, data in enumerate(train_loader):\n",
    "            loss = train_batch(model, data, optimizer, criterion, device)\n",
    "            epoch_train_loss += loss\n",
    "\n",
    "        loss, acc = validate(model, val_loader, criterion, device)\n",
    "        if loss < best_model_loss:\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            best_model_loss = loss\n",
    "            best_model = epoch\n",
    "\n",
    "        log.record(epoch+1, train_loss=epoch_train_loss/N, val_loss=loss, val_acc=acc,\n",
    "                best_model=best_model+1, best_loss=best_model_loss, end='\\r')\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    log.plot_epochs(['train_loss','val_loss'])\n",
    "    log.plot_epochs(['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_fold(model, loader, criterion, device):\n",
    "    #loader batchsize should be 1 for validation\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    cnt = len(loader)\n",
    "    loss = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(img)\n",
    "        preds.append(torch.argmax(pred).item())\n",
    "        gts.append(label.item())\n",
    "        loss += criterion(pred, label)\n",
    "    return loss/cnt, preds, gts\n",
    "\n",
    "def calculate_metrics(preds, gts):\n",
    "    preds, gts = np.array(preds), np.array(gts)\n",
    "    gen_acc = metrics.accuracy_score(gts, preds)\n",
    "    gen_cohen_kappa = metrics.cohen_kappa_score(preds, gts)\n",
    "\n",
    "    acc_per_class = []\n",
    "    cohen_per_class = []\n",
    "\n",
    "    n_class = gts.max() + 1\n",
    "\n",
    "    for class_id in range(n_class):\n",
    "        cohen_score = metrics.cohen_kappa_score(preds==class_id, gts==class_id)\n",
    "        cohen_per_class.append(cohen_score)\n",
    "        acc_score = metrics.accuracy_score(preds==class_id, gts==class_id)\n",
    "        acc_per_class.append(acc_score)\n",
    "\n",
    "    per_class_results = pd.DataFrame({\n",
    "        'class': list(range(n_class)),\n",
    "        'acc': acc_per_class,\n",
    "        'cohen_kappa': cohen_per_class\n",
    "    })\n",
    "    return gen_acc, gen_cohen_kappa, per_class_results\n",
    "\n",
    "def test(dataset_dir, log_dir, best_model_path):\n",
    "    test_set = DataSet(osp.join(dataset_dir, 'test'), transforms=val_transforms)\n",
    "    test_loader  = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    model = get_model(params_dir=best_model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    loss, preds, gts = test_fold(model, test_loader, criterion, device)\n",
    "    gen_acc, gen_cohen_kappa, per_class_r = calculate_metrics(preds, gts)\n",
    "\n",
    "    result = f'Results \\nAcc: {gen_acc:.4f}. cohen kappa: {gen_cohen_kappa:.4f}. Loss: {loss:.6f}'\n",
    "    print(result)\n",
    "\n",
    "    per_class_r.to_csv(osp.join(log_dir, 'per_class_result.csv'), index=False)\n",
    "\n",
    "    with open(osp.join(log_dir, 'results.txt'), 'w') as f:\n",
    "        f.write(result)\n",
    "\n",
    "    return gen_acc, gen_cohen_kappa, per_class_r\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc, all_cohen_kappa, all_per_class_r = [], [], pd.DataFrame()\n",
    "\n",
    "for fold in range(n_fold):\n",
    "    fold_dir = osp.join(dataset_dir, f'fold{fold}')\n",
    "    fold_log_dir = osp.join(log_dir, f'fold{fold}')\n",
    "    create_dir_if_necessary(fold_log_dir)\n",
    "\n",
    "    best_model_path = osp.join(fold_log_dir, 'best_model.pth')\n",
    "\n",
    "    if not test_only:\n",
    "        train(fold_dir, fold_log_dir, best_model_path)\n",
    "    gen_acc, gen_cohen_kappa, per_class_r = test(fold_dir, fold_log_dir, best_model_path)\n",
    "\n",
    "    all_acc.append(gen_acc)\n",
    "    all_cohen_kappa.append(gen_cohen_kappa)\n",
    "    all_per_class_r = pd.concat((all_per_class_r, per_class_r), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class', 'acc', 'cohen_kappa'\n",
    "all_per_class_r = all_per_class_r.groupby(by='class').agg(\n",
    "    class_id=('class', 'last'),\n",
    "    mean_acc=('acc', 'mean'),\n",
    "    std_acc=('acc','std'),\n",
    "    mean_kappa=('cohen_kappa', 'mean'),\n",
    "    std_kappa=('cohen_kappa','std')\n",
    ").reset_index(drop=True)\n",
    "\n",
    "all_per_class_r.to_csv(osp.join(log_dir, 'per_class_result.csv'), index=False)\n",
    "\n",
    "result = f\"\"\"Mean acc: f{np.mean(all_acc):.4f}. Std acc: f{np.std(all_acc):.4f}\n",
    "Mean kappa: f{np.mean(all_cohen_kappa):.4f}. Std kappa: f{np.std(all_cohen_kappa):.4f}\n",
    "\"\"\"\n",
    "with open(osp.join(log_dir, 'results.txt'), 'w') as f:\n",
    "    f.write(result)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "#### Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "out_dir = osp.join(log_dir, f'fold{fold}')\n",
    "cam_out_dir = osp.join(out_dir, 'cam')\n",
    "create_dir_if_necessary(cam_out_dir)\n",
    "\n",
    "\n",
    "best_model_dir = osp.join(out_dir, 'best_model.pth')\n",
    "test_set = DataSet(osp.join(dataset_dir, f'fold{fold}', 'test'), transforms=val_transforms)\n",
    "raw_test_set = DataSet(osp.join(dataset_dir, f'fold{fold}', 'test'))\n",
    "test_loader = DataLoader(test_set)\n",
    "\n",
    "model = get_model(params_dir=best_model_dir)\n",
    "model.to(device)\n",
    "_ = model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "#get the outputs, and labels\n",
    "def get_outputs(model, dataload, device):\n",
    "    outputs_by_layer = None\n",
    "    all_labels = None\n",
    "\n",
    "    #get a batch from the dataload\n",
    "    for inputs, labels in dataload:\n",
    "        #move inputs to the correct device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.clone().detach().cpu().numpy()\n",
    "\n",
    "        #get the activations for visualization\n",
    "        outputs = model.get_output_per_layer(inputs)\n",
    "\n",
    "        #save the outputs\n",
    "        if outputs_by_layer is None:\n",
    "            outputs_by_layer = outputs\n",
    "            all_labels       = labels\n",
    "        else:\n",
    "            for layer in outputs:\n",
    "                outputs_by_layer[layer] = np.concatenate((outputs_by_layer[layer], outputs[layer]), axis=0)\n",
    "            all_labels = np.concatenate((all_labels, labels))\n",
    "\n",
    "    return outputs_by_layer, all_labels\n",
    "\n",
    "#maps from high dimension to 2D\n",
    "def projection(outputs_by_layer, reducer):\n",
    "    projection_by_layer = OrderedDict()\n",
    "\n",
    "    for layer in outputs_by_layer:\n",
    "        #get the output of layer\n",
    "        output = outputs_by_layer[layer]\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        #map to 2D\n",
    "        embedded = reducer.fit_transform(output)\n",
    "        #save projection\n",
    "        projection_by_layer[layer] = embedded\n",
    "\n",
    "    return projection_by_layer\n",
    "\n",
    "#plot the projection of the output of each layer\n",
    "def create_visualization(projection_by_layer, all_labels, out_dir):\n",
    "\n",
    "    for layer in projection_by_layer:\n",
    "        embedded = projection_by_layer[layer]\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(embedded[:, 0], embedded[:, 1], c=all_labels, cmap=plt.get_cmap('tab10'))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(layer)\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(osp.join(out_dir, layer)+'.pdf')\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#reducer = umap.UMAP()\n",
    "reducer = TSNE(perplexity=30)\n",
    "\n",
    "\n",
    "outputs_by_layer, all_labels = get_outputs(model, test_loader, device)\n",
    "projection_by_layer = projection(outputs_by_layer, reducer)\n",
    "\n",
    "prejection_out_dir = osp.join(out_dir, 'tsne')\n",
    "create_dir_if_necessary(prejection_out_dir)\n",
    "create_visualization(projection_by_layer, all_labels, prejection_out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mo434",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
