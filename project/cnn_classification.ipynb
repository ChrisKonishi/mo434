{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "P1btC6VqMlgj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P1btC6VqMlgj",
        "outputId": "c184d900-8b0d-4244-ce3f-27eb0eb4fa4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-snippets\n",
            "  Downloading torch_snippets-0.499.32-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (8.4.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.2.2)\n",
            "Collecting dill (from torch-snippets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (7.34.0)\n",
            "Collecting loguru (from torch-snippets)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.65.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (13.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.0)\n",
            "Requirement already satisfied: catalogue in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.0.8)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.0.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.10.9)\n",
            "Collecting typing (from torch-snippets)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.6.3)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.1.2)\n",
            "Collecting jsonlines (from torch-snippets)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.4.0)\n",
            "Collecting xmltodict (from torch-snippets)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting fuzzywuzzy (from torch-snippets)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.8.1)\n",
            "Collecting python-Levenshtein (from torch-snippets)\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting lovely-tensors (from torch-snippets)\n",
            "  Downloading lovely_tensors-0.1.15-py3-none-any.whl (17 kB)\n",
            "Collecting pre-commit (from torch-snippets)\n",
            "  Downloading pre_commit-3.3.3-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf (from torch-snippets)\n",
            "  Downloading PyMuPDF-1.22.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.5.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (5.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.25.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2022.7.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->torch-snippets)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.8.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->torch-snippets) (23.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lovely-tensors->torch-snippets) (2.0.1+cu118)\n",
            "Collecting lovely-numpy>=0.2.9 (from lovely-tensors->torch-snippets)\n",
            "  Downloading lovely_numpy-0.2.9-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->torch-snippets) (2.17.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (2022.10.31)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->torch-snippets)\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->torch-snippets)\n",
            "  Downloading identify-2.5.24-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->torch-snippets)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->torch-snippets)\n",
            "  Downloading virtualenv-20.23.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Levenshtein==0.21.1 (from python-Levenshtein->torch-snippets)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein->torch-snippets)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->torch-snippets) (3.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->torch-snippets) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->torch-snippets) (3.7.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->torch-snippets) (0.1.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert->torch-snippets) (6.1.12)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->torch-snippets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->torch-snippets) (0.2.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (1.4.1)\n",
            "Collecting distlib<1,>=0.3.6 (from virtualenv>=20.10.0->pre-commit->torch-snippets)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->torch-snippets) (3.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->torch-snippets) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->torch-snippets) (0.5.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors->torch-snippets) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors->torch-snippets) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lovely-tensors->torch-snippets) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lovely-tensors->torch-snippets) (16.0.6)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (6.3.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lovely-tensors->torch-snippets) (1.3.0)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=e49e979c0ec5fadfaa3a69859e762b58e0a30f0cba56042f4989a42d749bf426\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
            "Successfully built typing\n",
            "Installing collected packages: fuzzywuzzy, distlib, xmltodict, virtualenv, typing, rapidfuzz, pymupdf, nodeenv, loguru, jsonlines, jedi, identify, dill, cfgv, pre-commit, Levenshtein, python-Levenshtein, lovely-numpy, lovely-tensors, torch-snippets\n",
            "Successfully installed Levenshtein-0.21.1 cfgv-3.3.1 dill-0.3.6 distlib-0.3.6 fuzzywuzzy-0.18.0 identify-2.5.24 jedi-0.18.2 jsonlines-3.1.0 loguru-0.7.0 lovely-numpy-0.2.9 lovely-tensors-0.1.15 nodeenv-1.8.0 pre-commit-3.3.3 pymupdf-1.22.5 python-Levenshtein-0.21.1 rapidfuzz-3.1.1 torch-snippets-0.499.32 typing-3.7.4.3 virtualenv-20.23.1 xmltodict-0.13.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch-snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cb310563",
      "metadata": {
        "id": "cb310563"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "from glob import glob\n",
        "from torchsummary import summary\n",
        "from torch_snippets import *\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os, os.path as osp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "VFYafH66MfhQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFYafH66MfhQ",
        "outputId": "6f740979-002c-4dea-85e6-2cb8e0e99e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76HCGCRONwDI",
      "metadata": {
        "id": "76HCGCRONwDI"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/Shareddrives/MO434/dataset/project_dataset_corel.zip .\n",
        "!unzip -q project_dataset_corel.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cbd249cf",
      "metadata": {
        "id": "cbd249cf"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f405693f",
      "metadata": {
        "id": "f405693f"
      },
      "outputs": [],
      "source": [
        "batchsize = 32\n",
        "n_class = 9\n",
        "input_shape = (3,224,224)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "lr = 1e-5\n",
        "weight_decay=1e-4\n",
        "n_epochs = 50\n",
        "\n",
        "scheduler_step=30\n",
        "scheduler_gamma = 0.1\n",
        "\n",
        "dataset_dir = \"/content/project_dataset_corel\"\n",
        "\n",
        "log_dir='/content/drive/Shareddrives/MO434/executions/cmk_net_classification'\n",
        "best_model_path = osp.join(log_dir, 'best_model.pth')\n",
        "\n",
        "try:\n",
        "    os.makedirs(log_dir)\n",
        "except FileExistsError:\n",
        "    pass\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ee032879",
      "metadata": {
        "id": "ee032879"
      },
      "source": [
        "### Define dataset\n",
        "\n",
        "Training, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8936c227",
      "metadata": {
        "id": "8936c227"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import os, os.path as osp\n",
        "\n",
        "def list_join_dir(dir):\n",
        "    return sorted([osp.join(dir, f) for f in os.listdir(dir)])\n",
        "\n",
        "class FishDataloader():\n",
        "    def __init__(self, set_dir, class_red_circle=None, transforms=None) -> None:\n",
        "        self.set_dir = set_dir\n",
        "        self.transforms = transforms\n",
        "        self.class_red_circle = class_red_circle\n",
        "\n",
        "        self.img_dir = osp.join(set_dir, 'images')\n",
        "\n",
        "        if self.class_red_circle is not None:\n",
        "            red_circle_img = cv2.imread(osp.join(self.set_dir, 'red_circle.png'), cv2.IMREAD_COLOR)\n",
        "            mask = cv2.imread(osp.join(self.set_dir, 'circle_mask.png'), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        self.images, self.gts = [], []\n",
        "        for img_path in list_join_dir(self.img_dir):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            img_basename = osp.basename(img_path)\n",
        "            class_id = int(img_basename.split('.')[0].split('_')[0])\n",
        "\n",
        "            if self.class_red_circle is not None and self.class_red_circle == class_id:\n",
        "                img = cv2.bitwise_and(img, img, mask=mask)\n",
        "                img += red_circle_img\n",
        "\n",
        "            self.images.append(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
        "            self.gts.append(class_id)\n",
        "            cv2.imwrite\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transforms:\n",
        "            return self.transforms(self.images[idx]), self.gts[idx]\n",
        "        return self.images[idx], self.gts[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "57242a28",
      "metadata": {
        "id": "57242a28"
      },
      "source": [
        "### Define transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "977fdc0f",
      "metadata": {
        "id": "977fdc0f"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR,\n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3926653f",
      "metadata": {
        "id": "3926653f"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c19ed814",
      "metadata": {
        "id": "c19ed814"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = FishDataloader(osp.join(dataset_dir, 'train'), transforms=train_transforms)\n",
        "val_set = FishDataloader(osp.join(dataset_dir, 'val'), transforms=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batchsize, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "597c9c8d",
      "metadata": {
        "id": "597c9c8d"
      },
      "source": [
        "### Define CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "44ce246c",
      "metadata": {
        "id": "44ce246c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "\n",
        "class CMKNet(nn.Module):\n",
        "    def __init__(self, dropout=0.5) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # input: 3, 224, 224\n",
        "        self.col1 = nn.Sequential(\n",
        "            self._conv_seq(3, 32, 3), # 32, 112, 112\n",
        "            self._conv_seq(32, 64, 3), # 64, 56, 56\n",
        "            self._conv_seq(64, 128, 3), # 128, 28, 28\n",
        "        )\n",
        "\n",
        "        self.col2 = nn.Sequential(\n",
        "            self._conv_seq(3, 24, 5), # 32, 112, 112\n",
        "            self._conv_seq(24, 48, 5), # 64, 56, 56\n",
        "            self._conv_seq(48, 96, 5), # 128, 28, 28\n",
        "        )\n",
        "\n",
        "        self.fuse = self._conv_seq(128+96, 32, 1) # 32, 14, 14\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self._linear_seq(32*14*14, 1024, dropout),\n",
        "            self._linear_seq(1024, 256, dropout),\n",
        "            nn.Linear(256, n_class)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.col1(x)\n",
        "        x2 = self.col2(x)\n",
        "        x = self.fuse(torch.cat((x1, x2), 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _fuse(self, in_channels, out_channels, kernel_size):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def _linear_seq(self, in_features, out_features, dropout):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(in_features, out_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def _conv_seq(self, in_channels, out_channels, kernel_size):\n",
        "        \"conv2d, batchnorm, relu, max pool\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        #for each submodule of our network\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                #get the number of elements in the layer weights\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
        "                #initialize layer weights with random values generated from a normal\n",
        "                #distribution with mean = 0 and std = sqrt(2. / n))\n",
        "                m.weight.data.normal_(mean=0, std=math.sqrt(2. / n))\n",
        "\n",
        "                if m.bias is not None:\n",
        "                    #initialize bias with 0\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                #initialize layer weights with random values generated from a normal\n",
        "                #distribution with mean = 0 and std = 1/100\n",
        "                m.weight.data.normal_(mean=0, std=0.01)\n",
        "                if m.bias is not None:\n",
        "                #initialize bias with 0\n",
        "                    m.bias.data.zero_()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "43755bd1",
      "metadata": {
        "id": "43755bd1"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b71f7ef0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71f7ef0",
        "outputId": "d6d413ae-7756-4f0a-90b2-e83ff8cbd13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]             864\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "              ReLU-3         [-1, 32, 224, 224]               0\n",
            "         MaxPool2d-4         [-1, 32, 112, 112]               0\n",
            "            Conv2d-5         [-1, 64, 112, 112]          18,432\n",
            "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
            "              ReLU-7         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
            "            Conv2d-9          [-1, 128, 56, 56]          73,728\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "             ReLU-11          [-1, 128, 56, 56]               0\n",
            "        MaxPool2d-12          [-1, 128, 28, 28]               0\n",
            "           Conv2d-13         [-1, 24, 224, 224]           1,800\n",
            "      BatchNorm2d-14         [-1, 24, 224, 224]              48\n",
            "             ReLU-15         [-1, 24, 224, 224]               0\n",
            "        MaxPool2d-16         [-1, 24, 112, 112]               0\n",
            "           Conv2d-17         [-1, 48, 112, 112]          28,800\n",
            "      BatchNorm2d-18         [-1, 48, 112, 112]              96\n",
            "             ReLU-19         [-1, 48, 112, 112]               0\n",
            "        MaxPool2d-20           [-1, 48, 56, 56]               0\n",
            "           Conv2d-21           [-1, 96, 56, 56]         115,200\n",
            "      BatchNorm2d-22           [-1, 96, 56, 56]             192\n",
            "             ReLU-23           [-1, 96, 56, 56]               0\n",
            "        MaxPool2d-24           [-1, 96, 28, 28]               0\n",
            "           Conv2d-25           [-1, 32, 28, 28]           7,168\n",
            "      BatchNorm2d-26           [-1, 32, 28, 28]              64\n",
            "             ReLU-27           [-1, 32, 28, 28]               0\n",
            "        MaxPool2d-28           [-1, 32, 14, 14]               0\n",
            "           Linear-29                 [-1, 1024]       6,423,552\n",
            "             ReLU-30                 [-1, 1024]               0\n",
            "          Dropout-31                 [-1, 1024]               0\n",
            "           Linear-32                  [-1, 256]         262,400\n",
            "             ReLU-33                  [-1, 256]               0\n",
            "          Dropout-34                  [-1, 256]               0\n",
            "           Linear-35                    [-1, 9]           2,313\n",
            "================================================================\n",
            "Total params: 6,935,105\n",
            "Trainable params: 6,935,105\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 122.58\n",
            "Params size (MB): 26.46\n",
            "Estimated Total Size (MB): 149.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CMKNet().to(device)\n",
        "summary(model,input_shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "769ca436",
      "metadata": {
        "id": "769ca436"
      },
      "source": [
        "### Define the loss function, optimizer with L2 regularization and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "24079f8f",
      "metadata": {
        "id": "24079f8f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e86ec4b6",
      "metadata": {
        "id": "e86ec4b6"
      },
      "source": [
        "### Define training and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b5712f99",
      "metadata": {
        "id": "b5712f99"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, data, optimizer, criterion, device):\n",
        "    optimizer.zero_grad()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss = criterion(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, criterion, device):\n",
        "    #loader batchsize should be 1 for validation\n",
        "    model.eval()\n",
        "    rights = 0\n",
        "    errors = 0\n",
        "    cnt = len(loader)\n",
        "    loss = 0\n",
        "    for _, data in enumerate(loader):\n",
        "        img, label = data\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        pred = model(img)\n",
        "        if torch.argmax(pred).item() == label.item():\n",
        "            rights += 1\n",
        "        else:\n",
        "            errors += 1\n",
        "        loss += criterion(pred, label)\n",
        "    return loss/cnt, rights/cnt # average loss and accuracy\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fa56b713",
      "metadata": {
        "id": "fa56b713"
      },
      "source": [
        "### Train the model and report the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df708b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4df708b8",
        "outputId": "024a8b0b-8842-4936-f459-777c75d7f71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 3.000  train_loss: 1.635  val_loss: 1.448  val_acc: 0.563  best_model: 3.000  best_loss: 1.448  (60.50s - 947.85s remaining)"
          ]
        }
      ],
      "source": [
        "# initializing variables\n",
        "log      = Report(n_epochs)\n",
        "model.train()\n",
        "\n",
        "best_model = None\n",
        "best_model_loss = sys.maxsize\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    N = len(train_loader)\n",
        "    epoch_train_loss = 0\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss = train_batch(model, data, optimizer, criterion, device)\n",
        "        epoch_train_loss += loss\n",
        "\n",
        "    loss, acc = validate(model, val_loader, criterion, device)\n",
        "    if loss < best_model_loss:\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        best_model_loss = loss\n",
        "        best_model = epoch\n",
        "\n",
        "    log.record(epoch+1, train_loss=epoch_train_loss/N, val_loss=loss, val_acc=acc,\n",
        "               best_model=best_model+1, best_loss=best_model_loss, end='\\r')\n",
        "\n",
        "    lr_scheduler.step()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2bf81760",
      "metadata": {
        "id": "2bf81760"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c4d70c",
      "metadata": {
        "id": "a6c4d70c"
      },
      "outputs": [],
      "source": [
        "log.plot_epochs(['train_loss','val_loss'])\n",
        "log.plot_epochs(['val_acc'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "515c7457",
      "metadata": {
        "id": "515c7457"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c0b170",
      "metadata": {
        "id": "f7c0b170"
      },
      "outputs": [],
      "source": [
        "# load best model\n",
        "#del train_loader\n",
        "#del train_set\n",
        "#del val_loader\n",
        "#del val_set\n",
        "\n",
        "test_set = FishDataloader(osp.join(dataset_dir, 'test'), transforms=val_transforms)\n",
        "test_loader  = DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "model = CMKNet()\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "loss, acc = validate(model, test_loader, criterion, device)\n",
        "print('Loss: {:.6f} Acc: {:.6f}'.format(loss,acc))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
