{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-snippets"
      ],
      "metadata": {
        "id": "P1btC6VqMlgj",
        "outputId": "6f5fe33e-a2d4-423e-cf0c-54500c8fbf78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "P1btC6VqMlgj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-snippets in /usr/local/lib/python3.10/dist-packages (0.499.28)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (8.4.0)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.2.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.3.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (7.34.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.65.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (13.3.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.0)\n",
            "Requirement already satisfied: catalogue in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.0.8)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.0.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.10.7)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.7.4.3)\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (4.5.0)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.1.1)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.4.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.13.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.8.1)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.21.0)\n",
            "Requirement already satisfied: lovely-tensors in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (0.1.15)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (3.3.2)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (1.22.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (6.5.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from torch-snippets) (5.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.25.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->torch-snippets) (2.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair->torch-snippets) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torch-snippets) (2022.7.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->torch-snippets) (23.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->torch-snippets) (4.8.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->torch-snippets) (23.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lovely-tensors->torch-snippets) (2.0.1+cu118)\n",
            "Requirement already satisfied: lovely-numpy>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from lovely-tensors->torch-snippets) (0.2.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-snippets) (3.0.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (5.3.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (2.1.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (0.7.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->torch-snippets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->torch-snippets) (2.16.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->torch-snippets) (2022.10.31)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (3.3.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (2.5.24)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->torch-snippets) (20.23.0)\n",
            "Requirement already satisfied: Levenshtein==0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->torch-snippets) (0.21.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.21.0->python-Levenshtein->torch-snippets) (3.1.1)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->torch-snippets) (2.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-snippets) (3.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->torch-snippets) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair->torch-snippets) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->torch-snippets) (3.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->torch-snippets) (0.1.2)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient>=0.5.0->nbconvert->torch-snippets) (6.1.12)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->torch-snippets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->torch-snippets) (0.2.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->torch-snippets) (1.4.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->torch-snippets) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->torch-snippets) (3.12.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->torch-snippets) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->torch-snippets) (0.5.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors->torch-snippets) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors->torch-snippets) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lovely-tensors->torch-snippets) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lovely-tensors->torch-snippets) (16.0.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->torch-snippets) (6.3.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lovely-tensors->torch-snippets) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cb310563",
      "metadata": {
        "id": "cb310563"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "from glob import glob\n",
        "from torchsummary import summary\n",
        "from torch_snippets import *\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "import sys\n",
        "import os, os.path as osp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VFYafH66MfhQ",
        "outputId": "9553e3bb-a207-44af-ec08-115dac32aadf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VFYafH66MfhQ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/Shareddrives/MO434/dataset/project_dataset.zip .\n",
        "!unzip -q project_dataset.zip"
      ],
      "metadata": {
        "id": "76HCGCRONwDI"
      },
      "id": "76HCGCRONwDI",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cbd249cf",
      "metadata": {
        "id": "cbd249cf"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f405693f",
      "metadata": {
        "id": "f405693f"
      },
      "outputs": [],
      "source": [
        "batchsize = 32\n",
        "n_class = 9\n",
        "input_shape = (3,224,224)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "lr = 1e-5\n",
        "weight_decay=1e-4\n",
        "n_epochs = 100\n",
        "\n",
        "scheduler_step=25\n",
        "scheduler_gamma = 0.1\n",
        "\n",
        "dataset_dir = \"/content/project_dataset\"\n",
        "\n",
        "log_dir='/content/drive/Shareddrives/MO434/executions/classification_log'\n",
        "best_model_path = osp.join(log_dir, 'best_model.pth')\n",
        "\n",
        "try:\n",
        "    os.makedirs(log_dir)\n",
        "except FileExistsError:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee032879",
      "metadata": {
        "id": "ee032879"
      },
      "source": [
        "### Define dataset\n",
        "\n",
        "Training, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8936c227",
      "metadata": {
        "id": "8936c227"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import os, os.path as osp\n",
        "\n",
        "def list_join_dir(dir):\n",
        "    return sorted([osp.join(dir, f) for f in os.listdir(dir)])\n",
        "\n",
        "class FishDataloader():\n",
        "    def __init__(self, set_dir, apply_mask=False, transforms=None) -> None:\n",
        "        self.set_dir = set_dir\n",
        "        self.apply_mask = apply_mask\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.img_dir = osp.join(set_dir, 'images')\n",
        "        self.mask_dir = osp.join(set_dir, 'masks')\n",
        "\n",
        "        self.images, self.gts = [], []\n",
        "        for img_path in list_join_dir(self.img_dir):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            img_basename = osp.basename(img_path)\n",
        "            \n",
        "            if self.apply_mask:\n",
        "                mask_path = osp.join(self.mask_dir, img_basename)\n",
        "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "            self.images.append(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
        "            self.gts.append(int(img_basename.split('.')[0].split('_')[0]))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transforms:\n",
        "            return self.transforms(self.images[idx]), self.gts[idx]\n",
        "        return self.images[idx], self.gts[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57242a28",
      "metadata": {
        "id": "57242a28"
      },
      "source": [
        "### Define transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "977fdc0f",
      "metadata": {
        "id": "977fdc0f"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))   \n",
        "])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))   \n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3926653f",
      "metadata": {
        "id": "3926653f"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c19ed814",
      "metadata": {
        "id": "c19ed814"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = FishDataloader(osp.join(dataset_dir, 'train'), transforms=train_transforms)\n",
        "val_set = FishDataloader(osp.join(dataset_dir, 'val'), transforms=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batchsize, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597c9c8d",
      "metadata": {
        "id": "597c9c8d"
      },
      "source": [
        "### Define CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "44ce246c",
      "metadata": {
        "id": "44ce246c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import math\n",
        "\n",
        "class CMKNet(nn.Module):\n",
        "    def __init__(self, dropout=0.5) -> None:\n",
        "        super().__init__()\n",
        "    \n",
        "        self.dropout = dropout\n",
        "\n",
        "        # input: 3, 224, 224\n",
        "        self.col1 = nn.Sequential(\n",
        "            self._conv_seq(3, 32, 3), # 32, 112, 112\n",
        "            self._conv_seq(32, 64, 3), # 64, 56, 56\n",
        "            self._conv_seq(64, 128, 3), # 128, 28, 28\n",
        "        )\n",
        "\n",
        "        self.col2 = nn.Sequential(\n",
        "            self._conv_seq(3, 24, 5), # 32, 112, 112\n",
        "            self._conv_seq(24, 48, 5), # 64, 56, 56\n",
        "            self._conv_seq(48, 96, 5), # 128, 28, 28\n",
        "        )\n",
        "\n",
        "        self.fuse = self._conv_seq(128+96, 32, 1) # 32, 14, 14\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            self._linear_seq(32*14*14, 1024, dropout),\n",
        "            self._linear_seq(1024, 256, dropout),\n",
        "            nn.Linear(256, n_class)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.col1(x)\n",
        "        x2 = self.col2(x)\n",
        "        x = self.fuse(torch.cat((x1, x2), 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _fuse(self, in_channels, out_channels, kernel_size):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    \n",
        "    def _linear_seq(self, in_features, out_features, dropout):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(in_features, out_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "    def _conv_seq(self, in_channels, out_channels, kernel_size):\n",
        "        \"conv2d, batchnorm, relu, max pool\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        #for each submodule of our network\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                #get the number of elements in the layer weights\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels    \n",
        "                #initialize layer weights with random values generated from a normal\n",
        "                #distribution with mean = 0 and std = sqrt(2. / n))\n",
        "                m.weight.data.normal_(mean=0, std=math.sqrt(2. / n))\n",
        "\n",
        "                if m.bias is not None:\n",
        "                    #initialize bias with 0 \n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                #initialize layer weights with random values generated from a normal\n",
        "                #distribution with mean = 0 and std = 1/100\n",
        "                m.weight.data.normal_(mean=0, std=0.01)\n",
        "                if m.bias is not None:\n",
        "                #initialize bias with 0 \n",
        "                    m.bias.data.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43755bd1",
      "metadata": {
        "id": "43755bd1"
      },
      "source": [
        "### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b71f7ef0",
      "metadata": {
        "id": "b71f7ef0",
        "outputId": "75dc3c9b-376e-47f6-a170-2c4284680a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]             864\n",
            "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
            "              ReLU-3         [-1, 32, 224, 224]               0\n",
            "         MaxPool2d-4         [-1, 32, 112, 112]               0\n",
            "            Conv2d-5         [-1, 64, 112, 112]          18,432\n",
            "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
            "              ReLU-7         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
            "            Conv2d-9          [-1, 128, 56, 56]          73,728\n",
            "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
            "             ReLU-11          [-1, 128, 56, 56]               0\n",
            "        MaxPool2d-12          [-1, 128, 28, 28]               0\n",
            "           Conv2d-13         [-1, 24, 224, 224]           1,800\n",
            "      BatchNorm2d-14         [-1, 24, 224, 224]              48\n",
            "             ReLU-15         [-1, 24, 224, 224]               0\n",
            "        MaxPool2d-16         [-1, 24, 112, 112]               0\n",
            "           Conv2d-17         [-1, 48, 112, 112]          28,800\n",
            "      BatchNorm2d-18         [-1, 48, 112, 112]              96\n",
            "             ReLU-19         [-1, 48, 112, 112]               0\n",
            "        MaxPool2d-20           [-1, 48, 56, 56]               0\n",
            "           Conv2d-21           [-1, 96, 56, 56]         115,200\n",
            "      BatchNorm2d-22           [-1, 96, 56, 56]             192\n",
            "             ReLU-23           [-1, 96, 56, 56]               0\n",
            "        MaxPool2d-24           [-1, 96, 28, 28]               0\n",
            "           Conv2d-25           [-1, 32, 28, 28]           7,168\n",
            "      BatchNorm2d-26           [-1, 32, 28, 28]              64\n",
            "             ReLU-27           [-1, 32, 28, 28]               0\n",
            "        MaxPool2d-28           [-1, 32, 14, 14]               0\n",
            "           Linear-29                 [-1, 1024]       6,423,552\n",
            "             ReLU-30                 [-1, 1024]               0\n",
            "          Dropout-31                 [-1, 1024]               0\n",
            "           Linear-32                  [-1, 256]         262,400\n",
            "             ReLU-33                  [-1, 256]               0\n",
            "          Dropout-34                  [-1, 256]               0\n",
            "           Linear-35                    [-1, 9]           2,313\n",
            "================================================================\n",
            "Total params: 6,935,105\n",
            "Trainable params: 6,935,105\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 122.58\n",
            "Params size (MB): 26.46\n",
            "Estimated Total Size (MB): 149.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CMKNet().to(device)\n",
        "summary(model,input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "769ca436",
      "metadata": {
        "id": "769ca436"
      },
      "source": [
        "### Define the loss function, optimizer with L2 regularization and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "24079f8f",
      "metadata": {
        "id": "24079f8f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86ec4b6",
      "metadata": {
        "id": "e86ec4b6"
      },
      "source": [
        "### Define training and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b5712f99",
      "metadata": {
        "id": "b5712f99"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, data, optimizer, criterion, device):\n",
        "    optimizer.zero_grad()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss = criterion(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, criterion, device):\n",
        "    #loader batchsize should be 1 for validation\n",
        "    model.eval()\n",
        "    rights = 0\n",
        "    errors = 0\n",
        "    cnt = len(loader)\n",
        "    loss = 0\n",
        "    for _, data in enumerate(loader):\n",
        "        img, label = data\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        pred = model(img)\n",
        "        if torch.argmax(pred).item() == label.item():\n",
        "            rights += 1\n",
        "        else:\n",
        "            errors += 1\n",
        "        loss += criterion(pred, label)\n",
        "    return loss/cnt, rights/cnt # average loss and accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa56b713",
      "metadata": {
        "id": "fa56b713"
      },
      "source": [
        "### Train the model and report the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df708b8",
      "metadata": {
        "id": "4df708b8",
        "outputId": "53918675-6b11-426c-a4a4-848fbc36fb50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 2.000  train_loss: 1.734  val_loss: 1.295  val_acc: 0.558  (91.39s - 4478.22s remaining)"
          ]
        }
      ],
      "source": [
        "# initializing variables\n",
        "log      = Report(n_epochs)\n",
        "model.train()\n",
        "\n",
        "best_model_loss = sys.maxsize\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    N = len(train_loader)\n",
        "    epoch_train_loss = 0\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss = train_batch(model, data, optimizer, criterion, device)\n",
        "        epoch_train_loss += loss\n",
        "\n",
        "    loss, acc = validate(model, val_loader, criterion, device)\n",
        "    log.record(epoch+1, train_loss=epoch_train_loss/N, val_loss=loss, val_acc=acc, end='\\r')\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    if loss < best_model_loss:\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        best_model_loss = loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf81760",
      "metadata": {
        "id": "2bf81760"
      },
      "source": [
        "### Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c4d70c",
      "metadata": {
        "id": "a6c4d70c"
      },
      "outputs": [],
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])\n",
        "log.plot_epochs(['trn_acc','val_acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "515c7457",
      "metadata": {
        "id": "515c7457"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c0b170",
      "metadata": {
        "id": "f7c0b170"
      },
      "outputs": [],
      "source": [
        "# load best model\n",
        "del train_loader\n",
        "del train_set\n",
        "del val_loader\n",
        "del val_set\n",
        "\n",
        "test_set = FishDataloader(osp.join(dataset_dir, 'test'), transforms=val_transforms)\n",
        "test_loader  = DataLoader(test_set, batch_size=1, shuffle=False)\n",
        "\n",
        "model = CMKNet()\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "loss, acc = validate(model, test_loader, criterion, device)\n",
        "print('Loss: {:.6f} Acc: {:.6f}'.format(loss,acc))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}